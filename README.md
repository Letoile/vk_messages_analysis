> В одном городе, одним вечером, один человек захотел поковырять API Вконтакте...

# Анализ сообщений ВК (частота слов)

На данный момент здесь представлен довольно топорный анализ (можно ли это считать анализом? :D) диалогов в ВК.

Здесь нет "умных" алгоритмов отбора слов. Только Python-обертка над API Вконтакте, регулярки и базовые возможности пакета Pandas.

При помощи API, получаем всю историю диалогов с определенным пользователем. После этого парсим полученную груду текста, разбираем на отдельные слова, и анализируем, какие же слова у нас оказались самыми часто употребляемыми.

## Как использовать?

1. Переходим на сайт https://vk.com/dev/ и создаем standalone app.
2. Читаем, как можно получить токен для приложения (нужные разрешения для этого приложения - messages) - https://vk.com/dev/auth_mobile
3. `cp config.example config.py`
4. В файле config.py определяем переменные APP_ID, TOKEN, MY_ID, FRIEND_ID, WORDS_COUNT (по дефолту == 20; кол-во слов, которые отобразятся в консоли после анализа)
5. Запускаем файл `get_messages_app.py` и уходим пить чай  :tea:, пока стягивается история сообщений, учитывая ограничение на 1 запрос в 3 секунды (время распития чая зависит от того, сколько времени вы провели в диалогах вк, вместо того, чтобы работать :grin:)
6. В корне проекта появится файл вида `messages_*FRIEND_ID*.txt`, содержащий всю историю переписки
7. После завершения работы, запускаем `get_statistics.py`, файл, который занимается непосредственно "анализом".
8. Скрипт отобразит в консоли 20 самых часто употребляемых слов (или то количество, которое определили в конфиге).  :memo: Можно добавить в код запись этих слов в файл :)
